{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77afd8b1-d66c-4b17-8561-e5950d26317b",
   "metadata": {},
   "source": [
    "#CSC2042S 2025\n",
    "## Assignment 2\n",
    "## Perceptron Image Classification\n",
    "### Maryam Abrahams (ABRMAR043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111b4480-88c1-4c80-af0b-0a8b6e5c6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089cbfc-1c2d-4216-b526-6d5f0fc7c837",
   "metadata": {},
   "source": [
    "## Task 1: Data Processing\n",
    "\n",
    "We start by loading the Simpsons-MNIST dataset from the directory structure and handling it so that we can create train/validation splits and prepare the data for the perceptron model.\n",
    "\n",
    "We'll do this by creating a function, load, which takes in the parameters (base_path: the path to the main dataset directory, mode: color vs gray, size: target image size ) and which returns a numpy array of converted images (both images and labels), as well as label_map: a dictionary mapping the folder names to numeric labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03950d65-8088-4a4a-ba8f-0b62a7b4e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "\n",
    "def load(base_path, mode=\"grayscale\", size = (28, 28)):\n",
    "\n",
    "    path = os.path.join(base_path, 'dataset', mode, 'train')\n",
    "    \n",
    "    characters = ['bart_simpson', 'charles_montgomery_burns', 'homer_simpson',\n",
    "                 'krusty_the_clown', 'lisa_simpson', 'marge_simpson',\n",
    "                 'milhouse_van_houten', 'moe_szyslak', 'ned_flanders',\n",
    "                 'principal_skinner']\n",
    "\n",
    "    label_map = {char: idx for idx, char in enumerate(characters)}\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    print(f\"Loading {mode} images from: {path}\\n\")\n",
    "\n",
    "    for character in characters: \n",
    "        char_path = os.path.join(path, character)\n",
    "\n",
    "        if not os.path.exists(char_path): \n",
    "            print(f\"Warning: Directory {char_path} does not exist\\n\")\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(char_path): \n",
    "            if file.endswith(\".jpg\"): \n",
    "                img_path = os.path.join(char_path, file)\n",
    "\n",
    "                try: \n",
    "                    with Image.open(img_path) as img: \n",
    "                        if mode == \"grayscale\": \n",
    "                            img = img.convert(\"L\") # make grescale\n",
    "                        else: \n",
    "                            img = img.convert(\"RGB\") # make colorful\n",
    "\n",
    "                        if img.size != size: \n",
    "                            img = img.resize(size)\n",
    "\n",
    "                        img_array = np.array(img)\n",
    "                        images.append(img_array) \n",
    "                        labels.append(label_map[character])\n",
    "                        \n",
    "                except Exception as e: \n",
    "                    print(f\"Error loading {img_path}: {e}\\n\")\n",
    "\n",
    "# Converting the images to numpy arrays\n",
    "    \n",
    "    X = np.array(images) \n",
    "    y = np.array(labels) \n",
    "\n",
    "    print(f\"Loaded {X.shape[0]} {mode} images with shape {X.shape[1:]}\\n\")\n",
    "    return X, y, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6a9ed8-214c-43b8-8dac-1029e4f62d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading grayscale images from: C:\\Users\\Yello\\OneDrive - University of Cape Town\\2025 Second Year\\Second Semester\\CSC2042S\\Assignment 2\\dataset\\grayscale\\train\n",
      "\n",
      "Loaded 8000 grayscale images with shape (28, 28)\n",
      "\n",
      "Loading rgb images from: C:\\Users\\Yello\\OneDrive - University of Cape Town\\2025 Second Year\\Second Semester\\CSC2042S\\Assignment 2\\dataset\\rgb\\train\n",
      "\n",
      "Loaded 8000 rgb images with shape (28, 28, 3)\n",
      "\n",
      "Grayscale data shape: (8000, 28, 28)\n",
      "RGB data shape: (8000, 28, 28, 3)\n",
      "Label mapping: {'bart_simpson': 0, 'charles_montgomery_burns': 1, 'homer_simpson': 2, 'krusty_the_clown': 3, 'lisa_simpson': 4, 'marge_simpson': 5, 'milhouse_van_houten': 6, 'moe_szyslak': 7, 'ned_flanders': 8, 'principal_skinner': 9}\n"
     ]
    }
   ],
   "source": [
    "# Loading both the gray and colored datasets: \n",
    "\n",
    "base_path = r\"C:\\Users\\Yello\\OneDrive - University of Cape Town\\2025 Second Year\\Second Semester\\CSC2042S\\Assignment 2\"\n",
    "\n",
    "try:\n",
    "    X_gray, y_gray, label_map = load(base_path, mode='grayscale')\n",
    "    X_rgb, y_rgb, _ = load(base_path, mode='rgb')\n",
    "    \n",
    "    print(f\"Grayscale data shape: {X_gray.shape}\")\n",
    "    print(f\"RGB data shape: {X_rgb.shape}\")\n",
    "    print(f\"Label mapping: {label_map}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Please check that the dataset path is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cb84c-d1df-4bb7-b589-d0719f222518",
   "metadata": {},
   "source": [
    "Next I'll create a function, splits, to create training and validation splits from the loaded data so that the stratified data is better understood. And in preparation for the perceptron implementation I'll normalize the data, creating multiple normalization options for better hyperparameter tuning later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a49323-9d4f-484a-bfbc-0b33f2503cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6400, 784), Validation set: (1600, 784)\n",
      "Training set: (6400, 2352), Validation set: (1600, 2352)\n"
     ]
    }
   ],
   "source": [
    "# Training and validation splits\n",
    "\n",
    "def splits(X, y, test_size = 0.2, random_state = 42, flatten = True): \n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state = random_state, stratify = y)\n",
    "\n",
    "    if flatten: \n",
    "        if len(X_train.shape) > 2: \n",
    "            X_train = X_train.reshape(X_train.shape[0], -1) \n",
    "            X_val = X_val.reshape(X_val.shape[0], -1) \n",
    "\n",
    "    print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}\")\n",
    "    return X_train, X_val, y_train, y_val\n",
    "    \n",
    "X_gray_train, X_gray_val, y_gray_train, y_gray_val = splits(X_gray, y_gray)\n",
    "X_rgb_train, X_rgb_val, y_rgb_train, y_rgb_val = splits(X_rgb, y_rgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e73fca8-f23a-445b-8086-b7919710d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized grayscale - Train range: [0.000, 1.00]\n"
     ]
    }
   ],
   "source": [
    "# Normalization options\n",
    "\n",
    "def normalize(X_train, X_val, method = \"none\"): \n",
    "\n",
    "    if method == \"minmax\": # to [0, 1]\n",
    "        X_train = X_train.astype('float32') / 255.0\n",
    "        X_val = X_val.astype('float32') / 255.0\n",
    "        \n",
    "    elif method == 'zscore':\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.astype('float32'))\n",
    "        X_val = scaler.transform(X_val.astype('float32'))\n",
    "        \n",
    "    elif method == 'none':\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_val = X_val.astype('float32')\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "X_gray_train_norm, X_gray_val_norm = normalize(X_gray_train, X_gray_val, 'minmax')\n",
    "print(f\"Normalized grayscale - Train range: [{X_gray_train_norm.min():.3f}, {X_gray_train_norm.max():.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff38c-7bfb-44cd-9944-1c67e334ad52",
   "metadata": {},
   "source": [
    "## Task 2: Multi-class Perceptron Implementation\n",
    "\n",
    "For our multi-class perceptron implementation, we  create both a binary perceptron and a multiclass perceptron class using the outline provided to us in the tutorials. For the multiclass implementation, it should be from scratch using a one-vs-rest approach, and for the binary version, we should implement the perceptron learning rule, plus a predict function to return a binary label, selecting the class with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa2f5cf-fb99-4565-8d3b-0c2b361b1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary perceptron class\n",
    "\n",
    "class BinaryPerceptron:\n",
    "\n",
    "    def __init__(self, n_features,learning_rate = 0.1, random_state = None):\n",
    "        self.weights = np.ones(n_features, dtype=float)\n",
    "        self.bias = 0.0\n",
    "        self.lr = learning_rate\n",
    "        self.errors = []\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x, dtype=float)\n",
    "        net_input = np.dot(x, self.weights) + self.bias\n",
    "        return 1 if net_input >= 0 else 0\n",
    "\n",
    "    def apply_learning_rule(self, x, y):\n",
    "        y_hat = self.predict(x)\n",
    "        error = y - y_hat\n",
    "        self.weights += self.lr * error * x\n",
    "        self.bias += self.lr * error\n",
    "        return abs(error)\n",
    "\n",
    "    def fit(self, X, y, max_epochs = 1000): \n",
    "        self.errors = []\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            total_error = 0\n",
    "            \n",
    "            for i in range(len(X)):\n",
    "                error = self.apply_learning_rule(X[i], y[i])\n",
    "                total_error += error\n",
    "            \n",
    "            self.errors.append(total_error)\n",
    "            if total_error == 0:\n",
    "                print(f\"Converged after {epoch + 1} epochs\")\n",
    "                break\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"BinaryPerceptron(weights={self.weights}, bias={self.bias:.3f}, learning rate={self.lr})\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bd4757-50d1-4d9a-bf16-6a65e9ce8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass perceptron\n",
    "\n",
    "class MulticlassPerceptron:\n",
    "\n",
    "    def __init__(self, n_features, n_classes =10, learning_rate =0.1, random_state = 42):\n",
    "        self.n_classes = n_classes\n",
    "        self.perceptrons = [\n",
    "            BinaryPerceptron(n_features, learning_rate, random_state + i) \n",
    "            for i in range(n_classes)\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y, max_epochs=1000):\n",
    "        for i in range(self.n_classes):\n",
    "            print(f\"Training perceptron for class {i}...\")\n",
    "            y_binary = np.where(y == i, 1, 0)\n",
    "            self.perceptrons[i].fit(X, y_binary, max_epochs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        scores = np.zeros((len(X), self.n_classes))\n",
    "        for i, perceptron in enumerate(self.perceptrons):\n",
    "            scores[:, i] = np.dot(X, perceptron.weights) + perceptron.bias\n",
    "        return np.argmax(scores, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab158e-9b03-449d-9afc-d301a1736d78",
   "metadata": {},
   "source": [
    "## Task 3: Training \n",
    "\n",
    "We seek to implement a training loop to find optimal weights and learning rules, the hyperparameters. By investigating two stopping criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816e4e44-ab37-4424-92a5-4c023ee9835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "class EnhancedBinaryPerceptron(BinaryPerceptron): \n",
    "\n",
    "    def __init__(self, n_features, learning_rate=0.1, random_state=None): \n",
    "        super().__init__(n_features, learning_rate, random_state)\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val =None, max_epochs = 1000, error_threshold=0.0, patience=5, verbose=True): \n",
    "        self.errors = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        # Collecting for early stopping: \n",
    "        best_weights = self.weights.copy()\n",
    "        best_bias = self.bias\n",
    "        best_val_acc = 0 \n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "\n",
    "            indices = np.random.permutation(len(X))\n",
    "            X_shuffled, y_shuffled = X[indices], y[indices]\n",
    "            \n",
    "            total_error = 0\n",
    "            for i in range(len(X)):\n",
    "                error = self.apply_learning_rule(X_shuffled[i], y_shuffled[i])\n",
    "                total_error += error\n",
    "            self.errors.append(total_error)\n",
    "\n",
    "            if X_val is not None and y_val is not None: \n",
    "                val_acc = self.accuracy(X_val, y_val)\n",
    "                self.val_accuracies.append(val_acc)\n",
    "                \n",
    "                # Early stop logic: \n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_weights = self.weights.copy()\n",
    "                    best_bias = self.bias\n",
    "                    patience_counter = 0\n",
    "                else: \n",
    "                    patience_counter += 1\n",
    "                if patience_counter >= patience: \n",
    "                    if verbose: \n",
    "                        print(f\"Early stopping at epoch {epoch+1}, best accuracy value: {best_val_acc:.4f}\")\n",
    "                        self.weights = best_weights\n",
    "                        self.bias = best_bias\n",
    "                        break\n",
    "                    \n",
    "            if total_error <= error_threshold:\n",
    "                if verbose: \n",
    "                    print(f\"Converged after {epoch + 1} epochs\")\n",
    "                break\n",
    "            if verbose and (epoch + 1) % 100 == 0: \n",
    "                print(f\"Epoch {epoch+1}, Training error: {total_error}\")\n",
    "                \n",
    "        if verbose and epoch == max_epochs - 1: \n",
    "            print(f\"Reached maximum epochs ({max_epochs})\")\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def accuracy(self, X, y): \n",
    "        predictions = np.array([self.predict(x) for x in X])\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "    def predict_score(self, x): \n",
    "        return np.dot(x, self.weights) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d7e1036-40a4-4a23-bd34-8d8ef94ddb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training binary labels for class 0:\n",
      "Class 0 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 0: 160, Others: 1440\n",
      "Early stopping at epoch 19, best accuracy value: 0.8994\n",
      "Final validation accuracy: 0.8994\n",
      "Epochs trained: 19\n",
      "\n",
      "Training binary labels for class 1:\n",
      "Class 1 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 1: 160, Others: 1440\n",
      "Early stopping at epoch 12, best accuracy value: 0.9012\n",
      "Final validation accuracy: 0.9012\n",
      "Epochs trained: 12\n",
      "\n",
      "Training binary labels for class 2:\n",
      "Class 2 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 2: 160, Others: 1440\n",
      "Early stopping at epoch 11, best accuracy value: 0.8981\n",
      "Final validation accuracy: 0.8981\n",
      "Epochs trained: 11\n",
      "\n",
      "Training binary labels for class 3:\n",
      "Class 3 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 3: 160, Others: 1440\n",
      "Early stopping at epoch 14, best accuracy value: 0.9000\n",
      "Final validation accuracy: 0.9000\n",
      "Epochs trained: 14\n",
      "\n",
      "Training binary labels for class 4:\n",
      "Class 4 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 4: 160, Others: 1440\n",
      "Early stopping at epoch 11, best accuracy value: 0.9000\n",
      "Final validation accuracy: 0.9000\n",
      "Epochs trained: 11\n",
      "\n",
      "Training binary labels for class 5:\n",
      "Class 5 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 5: 160, Others: 1440\n",
      "Early stopping at epoch 13, best accuracy value: 0.8994\n",
      "Final validation accuracy: 0.8994\n",
      "Epochs trained: 13\n",
      "\n",
      "Training binary labels for class 6:\n",
      "Class 6 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 6: 160, Others: 1440\n",
      "Early stopping at epoch 21, best accuracy value: 0.9006\n",
      "Final validation accuracy: 0.9006\n",
      "Epochs trained: 21\n",
      "\n",
      "Training binary labels for class 7:\n",
      "Class 7 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 7: 160, Others: 1440\n",
      "Early stopping at epoch 13, best accuracy value: 0.9031\n",
      "Final validation accuracy: 0.9031\n",
      "Epochs trained: 13\n",
      "\n",
      "Training binary labels for class 8:\n",
      "Class 8 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 8: 160, Others: 1440\n",
      "Early stopping at epoch 18, best accuracy value: 0.8956\n",
      "Final validation accuracy: 0.8956\n",
      "Epochs trained: 18\n",
      "\n",
      "Training binary labels for class 9:\n",
      "Class 9 samples: 640\n",
      "Other classes samples: 5760\n",
      "Validation - Class 9: 160, Others: 1440\n",
      "Early stopping at epoch 17, best accuracy value: 0.8988\n",
      "Final validation accuracy: 0.8988\n",
      "Epochs trained: 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Investigating stop conditions\n",
    "\n",
    "class_names = {\n",
    "    0: 'Bart Simpson',\n",
    "    1: 'Charles Montgomery Burns', \n",
    "    2: 'Homer Simpson',\n",
    "    3: 'Krusty the Clown',\n",
    "    4: 'Lisa Simpson',\n",
    "    5: 'Marge Simpson',\n",
    "    6: 'Milhouse Van Houten',\n",
    "    7: 'Moe Szyslak',\n",
    "    8: 'Ned Flanders',\n",
    "    9: 'Principal Skinner' \n",
    "}\n",
    "\n",
    "class_index = []\n",
    "convergence_epochs = []\n",
    "final_accuracy = []\n",
    "\n",
    "for i in range(0, 10): \n",
    "    \n",
    "    y_binary_train = np.where(y_gray_train == i, 1, 0)\n",
    "    y_binary_val = np.where(y_gray_val == i, 1, 0)\n",
    "    \n",
    "    print(f\"Training binary labels for class {i}:\")\n",
    "    class_index.append(i)\n",
    "    print(f\"Class {i} samples: {np.sum(y_binary_train == 1)}\")\n",
    "    print(f\"Other classes samples: {np.sum(y_binary_train == 0)}\")\n",
    "    print(f\"Validation - Class {i}: {np.sum(y_binary_val == 1)}, Others: {np.sum(y_binary_val == 0)}\")\n",
    "    \n",
    "    enhanced_perceptron = EnhancedBinaryPerceptron( n_features = X_gray_train_norm.shape[1], learning_rate = 0.1, random_state = 42 )\n",
    "\n",
    "    enhanced_perceptron.fit( X_gray_train_norm, y_binary_train, X_val = X_gray_val_norm, y_val=y_binary_val, max_epochs = 1000, patience = 10, verbose =True ) \n",
    "\n",
    "    acc = enhanced_perceptron.accuracy(X_gray_val_norm, y_binary_val) \n",
    "    final_accuracy.append(acc) \n",
    "    convergence_epochs.append(len(enhanced_perceptron.errors))\n",
    "    \n",
    "    print(f\"Final validation accuracy: {acc:.4f}\")\n",
    "    print(f\"Epochs trained: {len(enhanced_perceptron.errors)}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ffe42-f604-4d80-80d2-bdfd52255e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c4958e2-ad48-463e-ac5c-35663fbc9443",
   "metadata": {},
   "source": [
    "## Task 4: Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cc768-b344-4593-9ede-907581e89ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d33a4cc-39cc-4f2b-b74b-19c33f5bfd00",
   "metadata": {},
   "source": [
    "## Task 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81137e62-bc52-48ff-af93-02c46fbecea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bfcc0fe-79ed-49d8-bd52-964a6abb0577",
   "metadata": {},
   "source": [
    "## Task 6: RGB vs grayscale analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b18872-a90c-4434-8b84-1d5b72bbc12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
